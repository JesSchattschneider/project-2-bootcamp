{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['watertemp_bop.csv', 'watertemp_gb.csv', 'watertemp_tasman.csv', 'waves_bop.csv', 'waves_gb.csv', 'waves_tb.csv', 'winds_bop.csv', 'winds_gb.csv', 'winds_tb.csv']\n"
     ]
    }
   ],
   "source": [
    "# define path to read csvs\n",
    "path_csv = \"../data/\"\n",
    "\n",
    "# find all \".csv\" files in the path\n",
    "files = os.listdir(path_csv)\n",
    "files = [f for f in files if f.endswith('.csv')]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all csvs, saving each of them to a dataframe with the same name as the file\n",
    "for f in files:\n",
    "    name = f.split(\".\")[0]\n",
    "    # replace winds with wind in the name if it exists\n",
    "\n",
    "    name = name.replace(\"winds\", \"wind\")\n",
    "    # replace tasman with tb in the name\n",
    "    name = name.replace(\"tasman\", \"tb\")\n",
    "    # replace watertemp with water in the name\n",
    "    name = name.replace(\"watertemp\", \"water\")\n",
    "\n",
    "    # read csv\n",
    "    globals()[name] = pd.read_csv(path_csv + f)\n",
    "   \n",
    "    # add two columns to the df: dataType and deploymentId. These two values are informed in the name of the file separated by \"_\"\n",
    "    globals()[name][\"dataType\"] = name.split(\"_\")[0] + \"data\"\n",
    "    globals()[name][\"region\"] = name.split(\"_\")[1].split(\".\")[0]\n",
    "\n",
    "    \n",
    "    # add the name of the dataframe to the list of dataframes\n",
    "    if \"dataframes\" not in locals():\n",
    "        dataframes = [name]\n",
    "    else:\n",
    "        dataframes.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "\n",
    "def _observationDate2Isoformat(dt):\n",
    "    if dt.tzinfo is None:\n",
    "        raise ValueError(\"Datetime object must be timezone-aware\")\n",
    "\n",
    "    # Convert to UTC timezone\n",
    "    dt_utc = dt.astimezone(pytz.utc)\n",
    "\n",
    "    # Format in ISO 8601 with milliseconds\n",
    "    return dt_utc.isoformat()[:-6] + '.000Z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# path where the processed dataframes will be saved\n",
    "path_proc = \"../warehouse/seeds/\"\n",
    "\n",
    "for df_name in dataframes:\n",
    "    df = globals()[df_name]\n",
    "    \n",
    "    dataType = df[\"dataType\"].unique()[0]\n",
    "    df['time'] = pd.to_datetime(df['observationDate'], utc=True)\n",
    "    \n",
    "    # Extract fields based on field_mappings\n",
    "    # times_water = [parse(item[df['time']]) for item in df]\n",
    "    df['time'] = [_observationDate2Isoformat(i) for i in df['time']]\n",
    "\n",
    "    # Define field mappings based on data type for the dataframes\n",
    "    if dataType == 'waterdata':\n",
    "        field_mappings = {\n",
    "            'time': 'time',\n",
    "            'temperature': 'value', # cannot be values\n",
    "            'dataType': 'dataType',\n",
    "            'region': 'region'\n",
    "        }\n",
    "    elif dataType == 'winddata':\n",
    "        field_mappings = {\n",
    "            'time': 'time',\n",
    "            'windSpeed': 'speed',\n",
    "            'windGust': 'gust',\n",
    "            'windDirection': 'direction',\n",
    "            'dataType': 'dataType',\n",
    "            'region': 'region'\n",
    "        }\n",
    "    elif dataType == 'wavesdata':\n",
    "        field_mappings = {\n",
    "            'time': 'time',\n",
    "            'significantWaveHeight': 'significantHeight',\n",
    "            'maxWaveHeight': 'maxHeight',\n",
    "            'meanWaveDirection': 'direction',\n",
    "            'dataType': 'dataType',\n",
    "            'region': 'region'\n",
    "        }\n",
    "    # Extract fields based on field_mappings and keep only the columns that are in the field_mappings\n",
    "    df = df.rename(columns=field_mappings)\n",
    "    df = df[list(field_mappings.values())]\n",
    "    \n",
    "    # save the processed dataframe to a csv file\n",
    "    region = df[\"region\"].unique()[0]\n",
    "    dataType = df[\"dataType\"].unique()[0]\n",
    "\n",
    "    df.to_csv(path_proc + region + \"_\" + dataType + \"_hist.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
